2024-11-23 13:05:22,652 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Vision Query Generator, specifically designed to create clear and focused questions for vision models based on user tasks. Your role is to:\n\n1. Accept a task from a user\n2. Think step by step, and analyze what visual information would be needed to complete that task. \n3. Generate a precise question that will prompt a vision model to find and describe the relevant elements in an image\n\nWhen a user provides a task, you should:\n\nFirst detect what kind of picture would be required. Next, identify what visual elements would be critical for that task\nThen generate a question that combines:\n\n1. What specific items/elements to look for\n2. What characteristics of these items matter for the task\n3. What relationships or context needs to be described\n\nGiven a task in a json format:\n{{\n  "task": <task description>\n}}\nyou should generate a question in the format:\n{{\n    "task": <task description>,\n    "scene": <scene description>,\n    "question": <question description>\n}}\n'}, {'role': 'user', 'content': 'Task: I need to organize the pantry.\n```json\n'}], 'model': 'llama-3.1-70b-versatile', 'max_tokens': 1024, 'stop': None, 'stream': False, 'temperature': 1, 'top_p': 1}}
2024-11-23 13:05:22,713 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-11-23 13:05:22,713 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-23 13:05:22,746 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002495392EEA0>
2024-11-23 13:05:22,746 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000249539394D0> server_hostname='api.groq.com' timeout=5.0
2024-11-23 13:05:22,757 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000249533603E0>
2024-11-23 13:05:22,757 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-23 13:05:22,757 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-23 13:05:22,757 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-23 13:05:22,757 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-23 13:05:22,757 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-23 13:05:23,121 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 18:05:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5733'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'2.67s'), (b'x-request-id', b'req_01jdd36a0jfqpazzcr25ftjk2x'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ptcC7ZMaMw8MXYrMr4veluE8PxCmrEV2moD4NMavuqM-1732385122-1.0.1.1-3Yc_FECtM3yVzgsKt4vK4rDdWKsWFVTKBIQD63Cjy1Y.KTss2Ez9.cksmM2z_8Q_iQqTZEKHkqfdZrD_UPfBPQ; path=/; expires=Sat, 23-Nov-24 18:35:22 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e7316463feb36d5-YYZ'), (b'Content-Encoding', b'gzip')])
2024-11-23 13:05:23,122 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-23 13:05:23,123 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-23 13:05:23,123 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-23 13:05:23,123 - httpcore.http11 - DEBUG - response_closed.started
2024-11-23 13:05:23,123 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-23 13:05:23,124 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 23 Nov 2024 18:05:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5733', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '2.67s', 'x-request-id': 'req_01jdd36a0jfqpazzcr25ftjk2x', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=ptcC7ZMaMw8MXYrMr4veluE8PxCmrEV2moD4NMavuqM-1732385122-1.0.1.1-3Yc_FECtM3yVzgsKt4vK4rDdWKsWFVTKBIQD63Cjy1Y.KTss2Ez9.cksmM2z_8Q_iQqTZEKHkqfdZrD_UPfBPQ; path=/; expires=Sat, 23-Nov-24 18:35:22 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8e7316463feb36d5-YYZ', 'content-encoding': 'gzip'})
