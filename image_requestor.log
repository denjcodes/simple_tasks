2024-11-23 13:13:46,611 - __main__ - INFO - Generating request for task: I need to organize the pantry.
2024-11-23 13:13:46,613 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are helpful AI agent. Given a task description, you should request the user to take a picture of the relevant scene.\n\nWhen a user provides a task, you should generate a request for an image in the format:\nRequest: <request description>\n\nExample:\nTask: I need to clean this table.\nRequest: Please take a picture of the table.\n'}, {'role': 'user', 'content': 'Task: I need to organize the pantry.\nRequest: '}], 'model': 'llama-3.1-70b-versatile', 'max_tokens': 1024, 'stop': None, 'stream': False, 'temperature': 1, 'top_p': 1}}
2024-11-23 13:13:46,676 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-11-23 13:13:46,676 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-23 13:13:46,750 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235F90ACC50>
2024-11-23 13:13:46,750 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235F983D6D0> server_hostname='api.groq.com' timeout=5.0
2024-11-23 13:13:46,766 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235F912A1B0>
2024-11-23 13:13:46,766 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-23 13:13:46,767 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-23 13:13:46,767 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-23 13:13:46,767 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-23 13:13:46,767 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-23 13:13:46,939 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 18:13:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5897'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.03s'), (b'x-request-id', b'req_01jdd3np6cfdf9vbfn4ckp6czk'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TM0Y8xe33xFx7vW9_DEt_QCX9dUTUMqyxnlVYAm19Zo-1732385626-1.0.1.1-IrHfrNeF88.2rsGdUrSPsaYjFIQEGG7lgVqltUIhVTMx3ZnuMX5OtV0GMKm5d1fff3v6qTtuTcWJWC_eKPHgTg; path=/; expires=Sat, 23-Nov-24 18:43:46 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e73229439b2ac3a-YYZ'), (b'Content-Encoding', b'gzip')])
2024-11-23 13:13:46,940 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-23 13:13:46,940 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-23 13:13:46,940 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-23 13:13:46,941 - httpcore.http11 - DEBUG - response_closed.started
2024-11-23 13:13:46,941 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-23 13:13:46,941 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 23 Nov 2024 18:13:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5897', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.03s', 'x-request-id': 'req_01jdd3np6cfdf9vbfn4ckp6czk', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=TM0Y8xe33xFx7vW9_DEt_QCX9dUTUMqyxnlVYAm19Zo-1732385626-1.0.1.1-IrHfrNeF88.2rsGdUrSPsaYjFIQEGG7lgVqltUIhVTMx3ZnuMX5OtV0GMKm5d1fff3v6qTtuTcWJWC_eKPHgTg; path=/; expires=Sat, 23-Nov-24 18:43:46 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8e73229439b2ac3a-YYZ', 'content-encoding': 'gzip'})
2024-11-23 13:13:46,945 - __main__ - INFO - Generated request: Please take a picture of the pantry.
2024-11-23 13:13:46,946 - __main__ - INFO - Generating request for task: I need to identify and recycle.
2024-11-23 13:13:46,948 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are helpful AI agent. Given a task description, you should request the user to take a picture of the relevant scene.\n\nWhen a user provides a task, you should generate a request for an image in the format:\nRequest: <request description>\n\nExample:\nTask: I need to clean this table.\nRequest: Please take a picture of the table.\n'}, {'role': 'user', 'content': 'Task: I need to identify and recycle.\nRequest: '}], 'model': 'llama-3.1-70b-versatile', 'max_tokens': 1024, 'stop': None, 'stream': False, 'temperature': 1, 'top_p': 1}}
2024-11-23 13:13:46,948 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-11-23 13:13:46,949 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-23 13:13:46,949 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-23 13:13:46,949 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-23 13:13:46,949 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-23 13:13:46,950 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-23 13:13:47,138 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 18:13:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5776'), (b'x-ratelimit-reset-requests', b'11.826999999s'), (b'x-ratelimit-reset-tokens', b'2.231999999s'), (b'x-request-id', b'req_01jdd3npbyfek81ef8e3m0fynf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e7322955ae7ac3a-YYZ'), (b'Content-Encoding', b'gzip')])
2024-11-23 13:13:47,139 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-23 13:13:47,139 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-23 13:13:47,139 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-23 13:13:47,139 - httpcore.http11 - DEBUG - response_closed.started
2024-11-23 13:13:47,140 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-23 13:13:47,140 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 23 Nov 2024 18:13:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '5776', 'x-ratelimit-reset-requests': '11.826999999s', 'x-ratelimit-reset-tokens': '2.231999999s', 'x-request-id': 'req_01jdd3npbyfek81ef8e3m0fynf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8e7322955ae7ac3a-YYZ', 'content-encoding': 'gzip'})
2024-11-23 13:13:47,140 - __main__ - INFO - Generated request: Please take a picture of the items you want to identify and recycle.
2024-11-23 13:13:47,140 - __main__ - INFO - Generating request for task: I need to sort my laundry.
2024-11-23 13:13:47,141 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are helpful AI agent. Given a task description, you should request the user to take a picture of the relevant scene.\n\nWhen a user provides a task, you should generate a request for an image in the format:\nRequest: <request description>\n\nExample:\nTask: I need to clean this table.\nRequest: Please take a picture of the table.\n'}, {'role': 'user', 'content': 'Task: I need to sort my laundry.\nRequest: '}], 'model': 'llama-3.1-70b-versatile', 'max_tokens': 1024, 'stop': None, 'stream': False, 'temperature': 1, 'top_p': 1}}
2024-11-23 13:13:47,141 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-11-23 13:13:47,142 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-23 13:13:47,142 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-23 13:13:47,142 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-23 13:13:47,142 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-23 13:13:47,142 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-23 13:13:47,324 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 18:13:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14397'), (b'x-ratelimit-remaining-tokens', b'5662'), (b'x-ratelimit-reset-requests', b'17.8s'), (b'x-ratelimit-reset-tokens', b'3.378s'), (b'x-request-id', b'req_01jdd3npj8f3ts3gyzafsfqq0w'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e7322969c1cac3a-YYZ'), (b'Content-Encoding', b'gzip')])
2024-11-23 13:13:47,324 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-23 13:13:47,324 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-23 13:13:47,324 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-23 13:13:47,324 - httpcore.http11 - DEBUG - response_closed.started
2024-11-23 13:13:47,324 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-23 13:13:47,324 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 23 Nov 2024 18:13:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14397', 'x-ratelimit-remaining-tokens': '5662', 'x-ratelimit-reset-requests': '17.8s', 'x-ratelimit-reset-tokens': '3.378s', 'x-request-id': 'req_01jdd3npj8f3ts3gyzafsfqq0w', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8e7322969c1cac3a-YYZ', 'content-encoding': 'gzip'})
2024-11-23 13:13:47,325 - __main__ - INFO - Generated request: Please take a picture of the laundry items that need sorting.
2024-11-23 13:13:47,326 - __main__ - INFO - Generating request for task: I need to do gardening.
2024-11-23 13:13:47,327 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are helpful AI agent. Given a task description, you should request the user to take a picture of the relevant scene.\n\nWhen a user provides a task, you should generate a request for an image in the format:\nRequest: <request description>\n\nExample:\nTask: I need to clean this table.\nRequest: Please take a picture of the table.\n'}, {'role': 'user', 'content': 'Task: I need to do gardening.\nRequest: '}], 'model': 'llama-3.1-70b-versatile', 'max_tokens': 1024, 'stop': None, 'stream': False, 'temperature': 1, 'top_p': 1}}
2024-11-23 13:13:47,327 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-11-23 13:13:47,327 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-23 13:13:47,327 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-23 13:13:47,327 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-23 13:13:47,327 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-23 13:13:47,327 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-23 13:13:47,533 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 18:13:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14396'), (b'x-ratelimit-remaining-tokens', b'5550'), (b'x-ratelimit-reset-requests', b'23.821999999s'), (b'x-ratelimit-reset-tokens', b'4.498s'), (b'x-request-id', b'req_01jdd3npqwf3tvqvyam61tfshv'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e732297bd80ac3a-YYZ'), (b'Content-Encoding', b'gzip')])
2024-11-23 13:13:47,533 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-23 13:13:47,533 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-23 13:13:47,534 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-23 13:13:47,534 - httpcore.http11 - DEBUG - response_closed.started
2024-11-23 13:13:47,534 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-23 13:13:47,534 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 23 Nov 2024 18:13:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14396', 'x-ratelimit-remaining-tokens': '5550', 'x-ratelimit-reset-requests': '23.821999999s', 'x-ratelimit-reset-tokens': '4.498s', 'x-request-id': 'req_01jdd3npqwf3tvqvyam61tfshv', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8e732297bd80ac3a-YYZ', 'content-encoding': 'gzip'})
2024-11-23 13:13:47,535 - __main__ - INFO - Generated request: Please take a picture of the garden area that needs attention.
2024-11-23 13:13:47,536 - __main__ - INFO - Generating request for task: I need to repair my bike.
2024-11-23 13:13:47,536 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are helpful AI agent. Given a task description, you should request the user to take a picture of the relevant scene.\n\nWhen a user provides a task, you should generate a request for an image in the format:\nRequest: <request description>\n\nExample:\nTask: I need to clean this table.\nRequest: Please take a picture of the table.\n'}, {'role': 'user', 'content': 'Task: I need to repair my bike.\nRequest: '}], 'model': 'llama-3.1-70b-versatile', 'max_tokens': 1024, 'stop': None, 'stream': False, 'temperature': 1, 'top_p': 1}}
2024-11-23 13:13:47,536 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-11-23 13:13:47,538 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-23 13:13:47,538 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-23 13:13:47,538 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-23 13:13:47,538 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-23 13:13:47,538 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-23 13:13:48,051 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 18:13:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14395'), (b'x-ratelimit-remaining-tokens', b'5437'), (b'x-ratelimit-reset-requests', b'29.793s'), (b'x-ratelimit-reset-tokens', b'5.626999999s'), (b'x-request-id', b'req_01jdd3npydfdf8m8baqsr6hepd'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e7322990f22ac3a-YYZ'), (b'Content-Encoding', b'gzip')])
2024-11-23 13:13:48,051 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-23 13:13:48,051 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-23 13:13:48,052 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-23 13:13:48,052 - httpcore.http11 - DEBUG - response_closed.started
2024-11-23 13:13:48,052 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-23 13:13:48,052 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 23 Nov 2024 18:13:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14395', 'x-ratelimit-remaining-tokens': '5437', 'x-ratelimit-reset-requests': '29.793s', 'x-ratelimit-reset-tokens': '5.626999999s', 'x-request-id': 'req_01jdd3npydfdf8m8baqsr6hepd', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8e7322990f22ac3a-YYZ', 'content-encoding': 'gzip'})
2024-11-23 13:13:48,052 - __main__ - INFO - Generated request: Please take a picture of the area of the bike that needs repair.
2024-11-23 13:13:48,053 - __main__ - INFO - Generating request for task: I need to prepare my breakfast.
2024-11-23 13:13:48,055 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are helpful AI agent. Given a task description, you should request the user to take a picture of the relevant scene.\n\nWhen a user provides a task, you should generate a request for an image in the format:\nRequest: <request description>\n\nExample:\nTask: I need to clean this table.\nRequest: Please take a picture of the table.\n'}, {'role': 'user', 'content': 'Task: I need to prepare my breakfast.\nRequest: '}], 'model': 'llama-3.1-70b-versatile', 'max_tokens': 1024, 'stop': None, 'stream': False, 'temperature': 1, 'top_p': 1}}
2024-11-23 13:13:48,056 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-11-23 13:13:48,056 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-23 13:13:48,057 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-23 13:13:48,057 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-23 13:13:48,057 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-23 13:13:48,057 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-23 13:13:48,276 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 18:13:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14394'), (b'x-ratelimit-remaining-tokens', b'5352'), (b'x-ratelimit-reset-requests', b'35.481s'), (b'x-ratelimit-reset-tokens', b'6.475s'), (b'x-request-id', b'req_01jdd3nqemfek9kkd26vtpp91z'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e73229c4aa0ac3a-YYZ'), (b'Content-Encoding', b'gzip')])
2024-11-23 13:13:48,276 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-23 13:13:48,276 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-23 13:13:48,276 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-23 13:13:48,276 - httpcore.http11 - DEBUG - response_closed.started
2024-11-23 13:13:48,276 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-23 13:13:48,276 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 23 Nov 2024 18:13:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14394', 'x-ratelimit-remaining-tokens': '5352', 'x-ratelimit-reset-requests': '35.481s', 'x-ratelimit-reset-tokens': '6.475s', 'x-request-id': 'req_01jdd3nqemfek9kkd26vtpp91z', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8e73229c4aa0ac3a-YYZ', 'content-encoding': 'gzip'})
2024-11-23 13:13:48,277 - __main__ - INFO - Generated request: Please take a picture of your kitchen counter and any ingredients you plan to use for breakfast.
